{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "294d19c0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Deep Learning for Geo/Environmental sciences\n",
    "\n",
    "<center><img src=\"../logo_2.png\" alt=\"logo\" width=\"500\"/></center>\n",
    "\n",
    "<em>*Created with ChapGPT</em>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2b7a81",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Lecture 15: Large Language Models\n",
    "\n",
    " - [Recap](#Recap)\n",
    " - [Transformers](#Transformers)\n",
    " - [Large Language Models](#Large-Language-Models)\n",
    " - [Examples](#Examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7dc906",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Recap\n",
    "\n",
    "### VAEs, GANs, and Diffusion Models\n",
    "\n",
    "- **Variational Autoencoders (VAEs)**: Encode data into a latent space and decode it back, allowing for generation of new data.\n",
    "\n",
    "- **Generative Adversarial Networks (GANs)**: Consist of a generator and a discriminator, where the generator creates data and the discriminator evaluates it, leading to improved generation over time.\n",
    "\n",
    "- **Diffusion Models**: Start with noise and iteratively refine it to generate data, often producing high-quality outputs.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89929904",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Transformers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f692c2bf",
   "metadata": {},
   "source": [
    "![Transformers](./_images/transformer.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5549ab52",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Transformers - Key Concepts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a64aac5",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "**Self-Attention**: Mechanism that allows the model to weigh the importance of different words in a sequence, enabling it to capture long-range dependencies.\n",
    "\n",
    "This is important for understanding context in language, as it allows the model to focus on relevant parts of the input when making predictions, even if they are far apart in the sequence.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3df6aeb",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Positional Encoding**: Adds information about the position of words in a sequence, since transformers do not inherently understand order.\n",
    "\n",
    "For example, in a sentence like \"The cat sat on the mat,\" positional encoding helps the model differentiate between \"cat\" and \"mat\" based on their positions, which is crucial for understanding the meaning of the sentence.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ca5712",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "**Multi-Head Attention**: Uses multiple attention mechanisms in parallel, allowing the model to focus on different parts of the input simultaneously.\n",
    "\n",
    "This enables the model to capture various aspects of the input, such as different meanings or relationships between words, enhancing its understanding of complex sentences.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be126935",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Transformers - Architecture\n",
    "\n",
    "![Transformer Architecture](./_images/transformer_architecture.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e635f384",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Notes.\n",
    "- **Tokenization**: The input text is split into tokens, which can be words or subwords. Each token is then converted into a vector representation.\n",
    "- **Embedding Layer**: Converts tokens into dense vectors that capture semantic meaning. This is typically done using pre-trained embeddings like Word2Vec or GloVe, or learned during training.\n",
    "- **Positional Encoding**: Since transformers do not have a built-in sense of order, positional encodings are added to the token embeddings to provide information about the position of each token in the sequence.\n",
    "- **Attention Mechanism**: The core of the transformer, where each token attends to all other tokens in the sequence. This allows the model to weigh the importance of different tokens based on their context.\n",
    "- **Feed-Forward Networks**: Each layer includes a fully connected feed-forward network that processes the output of the self-attention mechanism.\n",
    "- **Softmax Layer**: At the output, a softmax layer is used to convert the final representations into probabilities for each token in the vocabulary, allowing for tasks like language modeling or text generation.\n",
    "\n",
    "Other important components:\n",
    "- **Layer Normalization**: Applied to stabilize and speed up training by normalizing the inputs to each layer.\n",
    "- **Residual Connections**: Allow gradients to flow through the network more easily, helping to mitigate the vanishing gradient problem in deep networks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031dd108",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Training\n",
    "\n",
    "Training transformers typically involves large datasets and significant computational resources. The training process includes:\n",
    "- **Pre-training**: The model is trained on a large corpus of text to learn general language representations. This phase often involves unsupervised learning tasks.\n",
    "- **Fine-tuning**: The pre-trained model is then fine-tuned on a specific task or dataset, such as sentiment analysis or translation, using supervised learning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5762d1de",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "Some example pre-training tasks include:\n",
    "- **Causal Language Modeling**: The model predicts the next word in a sequence given the previous words, which helps it learn the structure and flow of language.\n",
    "- **Masked Language Modeling**: Randomly masks some words in a sentence and trains the model to predict them based on the surrounding context, allowing it to learn relationships between words.\n",
    "- **Next Sentence Prediction**: The model learns to predict whether two sentences follow each other in the text, which helps it understand relationships between sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd13b9c2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Large Language Models (LLMs)\n",
    "\n",
    "Large Language Models (LLMs) are a class of deep learning models designed to understand and generate human language. They are built on the transformer architecture and are trained on vast amounts of text data to learn patterns, structures, and semantics of language."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ea4731",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "LLMs are characterized by their large number of parameters, often in the billions, which allows them to capture complex language features and relationships. They can perform a wide range of natural language processing tasks, including text generation, translation, summarization, and question answering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356c78ac",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Large Language Models (LLMs) - successes\n",
    "These models learn an underlying distribution of language, enabling them to generate coherent and contextually relevant text based on the input they receive. They can also adapt to various tasks with minimal fine-tuning, making them versatile tools in the field of natural language processing. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50eac8fe",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "One of the key successes of LLMs is their ability to scale effectively, meaning that as the model size increases (in terms of parameters), the performance on various language tasks tends to improve. This scalability is a significant factor in the development and deployment of LLMs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c414f9",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Large Language Models (LLMs) - challenges\n",
    "Although the output of LLMs can be highly convincing, it is important to note that they do not possess true understanding or consciousness; they generate text based on learned patterns rather than comprehension."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f74c7a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "LLMs can also inherit biases present in the training data, leading to biased outputs. Addressing these biases and ensuring fairness in their applications is a significant challenge."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676c8934",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "There are also ethical considerations surrounding the use of LLMs, including concerns about misinformation, privacy, and the potential for misuse in generating harmful content."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b54cc6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example usage of LLMs in practice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b54215",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's deploy a simple LLM using the Hugging Face Transformers library. This example will demonstrate how to use a pre-trained model for text generation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42028ede",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "# Load a pre-trained text generation model\n",
    "generator = pipeline('text-generation', model='gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50967ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate text based on a prompt\n",
    "prompt = \"Once upon a time in a galaxy far, far away\"\n",
    "generated_text = generator(prompt, max_length=50, num_return_sequences=1, truncation=True)\n",
    "\n",
    "# Print the generated text\n",
    "print(generated_text[0]['generated_text'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6032bf0f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Example with tool usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769f7c05",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Models that have been trained to use tools can perform tasks that require external knowledge or actions, such as searching the web, performing calculations, or interacting with APIs. This powerful capability allows them to provide more accurate and contextually relevant responses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138f07e2",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This code snippet uses the Hugging Face Transformers library to load a pre-trained GPT-2 model and generate text based on a given prompt. The `pipeline` function simplifies the process of using pre-trained models for various tasks, including text generation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010cb626",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from mlx_lm import generate, load\n",
    "from mlx_lm.models.cache import make_prompt_cache\n",
    "\n",
    "# Specify the checkpoint\n",
    "checkpoint = \"mlx-community/Qwen2.5-32B-Instruct-4bit\"\n",
    "\n",
    "# Load the corresponding model and tokenizer\n",
    "model, tokenizer = load(path_or_hf_repo=checkpoint)\n",
    "\n",
    "# An example tool, make sure to include a docstring and type hints\n",
    "def multiply(a: float, b: float):\n",
    "    \"\"\"\n",
    "    A function that multiplies two numbers\n",
    "\n",
    "    Args:\n",
    "        a: The first number to multiply\n",
    "        b: The second number to multiply\n",
    "    \"\"\"\n",
    "    return a * b\n",
    "\n",
    "\n",
    "tools = {\"multiply\": multiply}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea02ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Specify the prompt and conversation history\n",
    "prompt = \"Multiply 12234585 and 48838483920.\"\n",
    "messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "\n",
    "prompt = tokenizer.apply_chat_template(\n",
    "    messages, add_generation_prompt=True, tools=list(tools.values())\n",
    ")\n",
    "\n",
    "prompt_cache = make_prompt_cache(model)\n",
    "\n",
    "# Generate the initial tool call:\n",
    "response = generate(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    prompt=prompt,\n",
    "    max_tokens=2048,\n",
    "    verbose=True,\n",
    "    prompt_cache=prompt_cache,\n",
    ")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a5d674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the tool call:\n",
    "# (Note, the tool call format is model specific)\n",
    "tool_open = \"<tool_call>\"\n",
    "tool_close = \"</tool_call>\"\n",
    "start_tool = response.find(tool_open) + len(tool_open)\n",
    "end_tool = response.find(tool_close)\n",
    "tool_call = json.loads(response[start_tool:end_tool].strip())\n",
    "tool_result = tools[tool_call[\"name\"]](**tool_call[\"arguments\"])\n",
    "\n",
    "# Put the tool result in the prompt\n",
    "messages = [{\"role\": \"tool\", \"name\": tool_call[\"name\"], \"content\": tool_result}]\n",
    "prompt = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    add_generation_prompt=True,\n",
    ")\n",
    "\n",
    "# Generate the final response:\n",
    "response = generate(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    prompt=prompt,\n",
    "    max_tokens=2048,\n",
    "    verbose=True,\n",
    "    prompt_cache=prompt_cache,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2efa7252",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's try a more complex example \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a4ec9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"How many parameters does a NN with 50 inputs, 5 hidden layers, each 128 wide, and 2 outputs have?\"\n",
    "messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "\n",
    "prompt = tokenizer.apply_chat_template(\n",
    "    messages, add_generation_prompt=True, tools=list(tools.values())\n",
    ")\n",
    "\n",
    "prompt_cache = make_prompt_cache(model)\n",
    "\n",
    "# Generate the initial tool call:\n",
    "response = generate(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    prompt=prompt,\n",
    "    max_tokens=2048,\n",
    "    verbose=True,\n",
    "    prompt_cache=prompt_cache,\n",
    ")\n",
    "print(response)\n",
    "\n",
    "# Parse the tool call:\n",
    "# (Note, the tool call format is model specific)\n",
    "tool_open = \"<tool_call>\"\n",
    "tool_close = \"</tool_call>\"\n",
    "start_tool = response.find(tool_open) + len(tool_open)\n",
    "end_tool = response.find(tool_close)\n",
    "tool_call = json.loads(response[start_tool:end_tool].strip())\n",
    "tool_result = tools[tool_call[\"name\"]](**tool_call[\"arguments\"])\n",
    "\n",
    "# Put the tool result in the prompt\n",
    "messages = [{\"role\": \"tool\", \"name\": tool_call[\"name\"], \"content\": tool_result}]\n",
    "prompt = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    add_generation_prompt=True,\n",
    ")\n",
    "\n",
    "# Generate the final response:\n",
    "response = generate(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    prompt=prompt,\n",
    "    max_tokens=2048,\n",
    "    verbose=True,\n",
    "    prompt_cache=prompt_cache,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7114dff8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Multimodal Models\n",
    "\n",
    "LLMs are now evolving into multimodal models, which can process and generate content across different types of data, such as text, images, and audio. These models leverage the strengths of transformers to handle multiple modalities simultaneously, enabling them to understand and generate complex content that combines various forms of information.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3221bece",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "A key challenge in multimodal models is effectively integrating and aligning different types of data, such as text and images, to ensure that the model can understand the relationships between them. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903139d8",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "The first step in this process is to tokenize and encode each modality separately, allowing the model to learn representations that capture the unique characteristics of each type of data. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4388672a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Multimodal Models\n",
    "\n",
    "The model then uses cross-modal attention mechanisms to learn how different modalities relate to each other, enabling it to generate coherent outputs that combine information from multiple sources.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9421edc8",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "For example, models like CLIP (Contrastive Language-Image Pre-training) and DALL-E combine text and image understanding, enabling them to generate images from textual descriptions or vice versa.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d4b1c6",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## What about scientific data?\n",
    "\n",
    "Along these lines, there is growing interest in adapting LLMs to handle scientific data. Scientific data often involves complex structures, relationships, and domain-specific knowledge that differ from general language tasks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ef8e5a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "With sufficient training and adaptation, LLMs could potentially revolutionize how we interact with scientific literature and data. Some potential applications include:\n",
    "- **Automated Literature Review**: LLMs could assist researchers in quickly summarizing and extracting key information from vast amounts of scientific literature, saving time and effort in the research process.\n",
    "- **Data Extraction**: They could be used to extract relevant data from scientific texts, such as experimental results or methodologies, enabling more efficient data analysis and integration.\n",
    "- **Hypothesis Generation**: LLMs could help generate new hypotheses based on existing research, potentially leading to novel discoveries and insights.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814f80f7",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "However, adapting LLMs to scientific data presents several challenges:\n",
    "- **Domain-Specific Knowledge**: Scientific texts often contain specialized terminology and concepts that require a deep understanding of the domain. LLMs need to be trained on domain-specific data to effectively handle these nuances.\n",
    "- **Data Structure**: Scientific data can be structured in various formats, such as tables, graphs, and equations. LLMs need to be able to process and understand these different formats to extract meaningful information.\n",
    "- **Interpretability**: Scientific research often requires a high level of interpretability and explainability. LLMs need to provide clear and understandable explanations for their outputs, especially when generating hypotheses or summarizing complex data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b363ca6",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## What about scientific data?\n",
    "\n",
    "In collaboration with experts in Computer Science we are currently working on a project to adapt LLMs to scientific data, focusing on improving their ability to understand and generate scientific content. \n",
    "\n",
    "One of the main challenges is usefully encoding the scientific data, which often involves complex structures and relationships that are not easily captured by standard text-based models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a09c54",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "## Conclusion\n",
    "Large Language Models (LLMs) represent a significant advancement in the field of artificial intelligence, enabling machines to understand and generate human-like text. Their applications span various domains, from natural language processing to computer vision and beyond. However, challenges such as bias, interpretability, and resource requirements remain critical areas for ongoing research and development.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98234f73",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "As LLMs continue to evolve, their potential to transform industries and improve human-computer interaction is immense. The future of LLMs lies in addressing these challenges while expanding their capabilities to handle more complex and diverse data types, including scientific data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3fe610",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## SIO209 - Final remarks\n",
    "\n",
    "Through this course, we have covered a wide range of topics in deep learning for geo/environmental sciences, from the basics of neural networks to advanced topics like self-supervised learning and generative models. I hope you have gained a good understanding of these topics and how they can be applied to geospatial and environmental data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83528ea",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "We only scratched the surface of deep learning in this course, and there is much more to learn and explore. I encourage you to continue learning and experimenting with deep learning techniques and apply them to your own research or projects.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd11ba80",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "If you have any questions or need further clarification on any of the topics covered in this course, please feel free to reach out to me. I'm always happy to help and discuss deep learning with you.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4fb6bdc",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![I Learned Deep Learning](./_images/learned_deep_learning.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85e9303",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Evals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e0b8e3",
   "metadata": {},
   "source": [
    "\n",
    "Please fill out the course evaluation form to provide feedback on the course and help me improve it for future iterations. Your feedback is valuable and will help me make this course better for future students."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
